{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO en Tiempo Real: Detección de Objetos\n",
    "### Percepción Computacional - Universidad de los Hemisferios\n",
    "#### Maestría en Inteligencia Artificial Aplicada\n",
    "\n",
    "Bienvenidos a este cuaderno de Jupyter, donde exploraremos la emocionante tarea de la detección de objetos en tiempo real utilizando YOLO (You Only Look Once), una técnica avanzada de visión por computadora. Esta experiencia de aprendizaje forma parte del programa de la Maestría en Inteligencia Artificial Aplicada, impartido por la Universidad de los Hemisferios.\n",
    "\n",
    "En este cuaderno, aprenderás a utilizar YOLO para identificar y localizar diversos objetos en imágenes y secuencias de video. Esta habilidad es esencial en una amplia gama de aplicaciones, desde la conducción autónoma hasta la vigilancia de seguridad, y representa uno de los avances más emocionantes en el campo de la inteligencia artificial y la visión por computadora.\n",
    "\n",
    "A lo largo de este curso, explorarás conceptos clave como:\n",
    "\n",
    "- Detección de objetos en tiempo real.\n",
    "- Configuración de modelos YOLO pre-entrenados.\n",
    "- Interpretación de resultados de detección.\n",
    "- Aplicaciones prácticas de la detección de objetos.\n",
    "\n",
    "¡Prepárate para sumergirte en un emocionante mundo de visión por computadora y adquirir habilidades valiosas que te servirán en tu carrera en inteligencia artificial y más allá!\n",
    "\n",
    "Recuerda consultar este cuaderno para acceder a los recursos y ejemplos que te ayudarán a comprender YOLO y la percepción computacional en tiempo real.\n",
    "\n",
    "Eugenio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código utiliza el comando `!pip` para instalar dos paquetes de Python: `opencv-python` y `ultralytics`.\n",
    "\n",
    "- `opencv-python`: Esta es una biblioteca popular para tareas de visión por computadora en Python. Proporciona una variedad de funciones para el procesamiento de imágenes y videos, incluyendo detección de objetos, manipulación de imágenes y extracción de características.\n",
    "\n",
    "- `ultralytics`: Esta es una biblioteca construida sobre PyTorch, que se enfoca principalmente en tareas de visión por computadora como detección de objetos y clasificación de imágenes. Proporciona interfaces fáciles de usar para entrenar y evaluar modelos de aprendizaje profundo para estas tareas.\n",
    "\n",
    "Al ejecutar este comando, estás instalando estos paquetes en tu entorno de Python para que puedas usarlos en tu código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalamos las librerías necesarias\n",
    "!pip install opencv-python ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fragmento de código importa tres bibliotecas en Python:\n",
    "\n",
    "1. `ultralytics`: Esta es una biblioteca que proporciona una interfaz para usar modelos de detección de objetos YOLO (You Only Look Once). Permite entrenar, evaluar y utilizar modelos de detección de objetos de manera eficiente.\n",
    "\n",
    "2. `cv2` (OpenCV): Esta es una biblioteca popular para el procesamiento de imágenes y videos en Python. Proporciona una amplia gama de funciones para trabajar con imágenes y videos, incluyendo cargar imágenes, realizar operaciones de procesamiento de imágenes, y mostrar imágenes en una ventana, entre otros.\n",
    "\n",
    "3. `math`: Este es un módulo estándar de Python que proporciona funciones matemáticas comunes, como funciones trigonométricas, logarítmicas y aritméticas.\n",
    "\n",
    "El código importa estas bibliotecas para utilizarlas en el resto del programa, pero en este fragmento específico no se están utilizando ninguna función o clase de estas bibliotecas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo YOLO pre-entrenado en COCO dataset\n",
    "model = YOLO(\"yolo-Weights/yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos las clases que puede detectar el modelo\n",
    "model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista de nombres con todas las clases para identificar objetos detectados\n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n",
    "              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n",
    "              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n",
    "              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n",
    "              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n",
    "              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n",
    "              \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "              ] # Aquí se enumeran todas las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista de nombres de clases para identificar objetos detectados en una imagen \n",
    "classNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n",
    "              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"horse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 07:19:54.838 Python[54595:4275499] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-06-16 07:19:57.448 Python[54595:4275499] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importamos la biblioteca de OpenCV\n",
    "import cv2\n",
    "\n",
    "# Configuramos la captura de video desde la cámara\n",
    "captura = cv2.VideoCapture(0) # Se abre la cámara por defecto\n",
    "\n",
    "# Establecemos el ancho y alto de la imagen\n",
    "captura.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # Ancho de la imagen\n",
    "captura.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # Alto de la imagen\n",
    "\n",
    "# Iniciamos un bucle para procesar los fotogramas de la cámara\n",
    "while True:\n",
    "    # Capturamos un fotograma\n",
    "    exito, imagen = captura.read()\n",
    "\n",
    "    # Si la captura fue exitosa, mostramos la imagen\n",
    "    if exito:\n",
    "        cv2.imshow('Webcam', imagen)\n",
    "    else:\n",
    "        print(\"Error al capturar el fotograma\")\n",
    "\n",
    "    # Salimos del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Configuramos la captura de video desde la cámara\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# Se abre la cámara por defecto\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m640\u001b[39m) \u001b[38;5;66;03m# Ancho de la imagen\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cap\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m480\u001b[39m) \u001b[38;5;66;03m# Alto de la imagen\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Configuramos la captura de video desde la cámara\n",
    "cap = cv2.VideoCapture(0) # Se abre la cámara por defecto\n",
    "cap.set(3, 640) # Ancho de la imagen\n",
    "cap.set(4, 480) # Alto de la imagen\n",
    "\n",
    "# Iniciamos un bucle para procesar los fotogramas de la cámara\n",
    "while True:\n",
    "    success, img = cap.read() # Capturamos un fotograma\n",
    "\n",
    "    # Realizamos la detección de objetos en la imagen capturada (usando el modelo de YOLO pre-entrenado que cargamos anteriormente)\n",
    "    results = model(img, stream=True)\n",
    "\n",
    "   # Procesamos los resultados de la detección\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        # Iteramos sobre las cajas delimitadoras detectadas\n",
    "        for box in boxes:\n",
    "            # Obtenemos las coordenadas de la caja delimitadora\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # Convertimos a valores enteros\n",
    "\n",
    "            # Dibujamos la caja delimitadora en la imagen\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 1)\n",
    "\n",
    "            # Obtenemos la confianza de la detección\n",
    "            confidence = math.ceil((box.conf[0]*100))/100\n",
    "            print(\"Confidence --->\",confidence)\n",
    "\n",
    "            # Obtenemos el nombre de la clase detectada\n",
    "            cls = int(box.cls[0])\n",
    "            print(\"Class name -->\", classNames[cls])\n",
    "\n",
    "            # Mostramos el nombre de la clase junto a la caja delimitadora\n",
    "            org = [x1, y1]\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            fontScale = 1\n",
    "            color = (255, 0, 0) # Color: Azul (formato BGR)\n",
    "            thickness = 1\n",
    "            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n",
    "\n",
    "    # Mostramos la imagen con las detecciones\n",
    "    cv2.imshow('Webcam', img)\n",
    "\n",
    "    # Salimos del bucle si se presiona la tecla 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberamos la cámara y cerramos todas las ventanas\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
